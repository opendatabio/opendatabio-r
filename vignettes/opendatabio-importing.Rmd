---
title: "opendatabio:importing"
author: "A. Chalom & A. Vicentini"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Importing data using the OpenDataBio R client}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
# Importing data using the OpenDataBio R client

The `opendatabio` R package was created to allow data from an OpenDataBio server to be read, and to allow data to be easily imported to an OpenDataBio server. This vignette focus on data imports.

# Setting up the connection

The first thing to do when starting the data import is to correctly set up the connection to the OpenDataBio server using the `odb_config()` function or using the shell environment configuration.

See the "opendatabio-reading" vignette for details on how to use it.

```
cfg = odb_config(base_url = "http://opendatabio.ib.usp.br/opendatabio/api",token="YourToken")
```

# OpenDataBio import functions
All import functions have the same signature: the first argument is a `data.frame` with data to be imported, and the second parameter is a configuration object (generated by `odb_config`).

When writing an import request, check the [OpenDataBio API endpoints documentation](https://github.com/opendatabio/opendatabio/wiki/API-v0-endpoints) in order to understand which columns can be declared in the `data.frame`. 

All import functions return a job id, which can be used to check if the job is still running, if it ended with success or if it encountered an error. This job id can be used in the functions `odb_get_jobs()`, `odb_get_affected_ids()` and `odb_get_log()`, to find details about the job, which (if any) were the IDs of the successfully imported objects, and the full log of the job.

**Order is Important** - correctly importing data may depend on already registered records. For example, importing an Individual with a Taxon identity requires the taxon name registered in the database, so you would first validate your taxon list and then import the Individual records. 

```
odb_import_persons(data, cfg)
Sending ODB request (filesize = 1856)
    id    created_at (...) Status
    127   2018-03-07 (...) Submitted
odb_get_affected_ids(127, cfg)
[1] 41 42
odb_get_log(127, cfg)
[1] "WARNING: There is another registry of a person with name like João da Silva or abbreviation like SILVA, J."
```
## Importing locations

Working with spatial data is a very delicate area, so we have attempted to make the workflow for inserting locations as easy as possible.
You should use the web interface for large uploads, which will handle better memory issues. 

If you want to upload administrative boundaries for a country, you may also just download a [geojson](https://geojson.org/) file from  [OSM-Boundaries](https://osm-boundaries.com/) and upload it through the web interface directly.  

Locations may be POLYGONS (POLYGON OR MULTIPOLYGON), POINTS (latitude and longitude) or PLOTS. Importation is straightforward, but the main issues to keep in mind:

1. Locations are hierarchical, so a location MUST lie completely within its parent location. If a children polygon does not lie completely within its informed parent, OpenDataBio will fail to recognize the parent. This may happen, for example, when importing imprecise administrative boundaries from http://gadm.org, or mixing GADM data with administrative polygons from other sources. Adding a small buffer to the parent, downloading a different source or fixing the boundaries are possible solutions if you encounter these problems. Alternatively, you may just pass 'parent=0', and the location will be placed without a parent (in locations root, or World);
1. Consider, uploading your political administrative polygons before adding specific POINT or polygon locations;
1. Conservation Units are treated as special case by OpenDataBio, as some UCs may span different administrative locations. So a Location may belong to a UC in addition to its parent location. Therefore, UCs (adm_level==99) my be used to store any territorial area that transcends country administrative boundaries, and so are also usefull to store Indigenous Territories;
1. OpenDataBio stores the geometries of locations using Well-known text (WKT) representation.

### Adm_level defines the hierarchy

Location data are hierarchical and you should consider to seed your database with administrative polygons prior to enter POINT or PLOT locations.  The administrative level (adm_level) of a location is a number:  

* 2 for country; 3 to 10 as other as 'administrative areas', following [OpenStreeMap convention](https://wiki.openstreetmap.org/wiki/Tag:boundary%3Dadministrative#10_admin_level_values_for_specific_countries) to facilitate external data importation and local translations (TO BE IMPLEMENTED). So, for Brazil, codes are (States=4, Municipalities=8);
* 100 is the code for plots and subplots;
* 999 for 'POINT' locations like GPS waypoints; 
* 99 is the code for Conservation Units or Indigenous Territories;
* 101 for transects

### Importing spatial polygons

#### Administrative boundaries from GADM

To import administrative boundaries, which are POLYGONS, you may download the needed areas from GADM and easily import them into OpenDataBio:

```
library(raster)
library(opendatabio)
#download GADM administrative areas for a country

#get country codes
crtcodes = getData('ISO3')
bra = crtcodes[crtcodes$NAME%in%"Brazil",]

#define a path where to save the downloaded spatial data
path = "GADMS"
dir.create(path,showWarnings = F)

#the number of admin_levels in each country varies
#get all levels that exists into your computer
runit =T
level = 0
while(runit) {
   ocrt <- try(getData('GADM', country=bra, level=level,path=path),silent=T)
   if (class(ocrt)=="try-error") {
      runit = FALSE
   }
   level = level+1
}

#read downloaded data and format to odb
files = list.files(path, full.name=T)
locations.to.odb = NULL
for(f in 1:length(files)) {
   ocrt <- readRDS(files[f])
   #class(ocrt)
   #convert the SpatialPolygonsDataFrame to OpenDataBio format
   ocrt.odb = opendatabio:::sp_to_df(ocrt)  #only for GADM data
   locations.to.odb = rbind(locations.to.odb,ocrt.odb)
}
#see without geometry
head(locations.to.odb[,-ncol(locations.to.odb)])

#you may add a note to location
locations.to.odb$notes = paste("Source gdam.org via raster::get_data()",Sys.Date())

odb_import_locations(data=locations.to.odb,odb_cfg=cfg)

#ATTENTION: you may want to check for uniqueness of name+parent rather than just name, as name+parent are unique for locations. You may not save two locations with the same name within the same parent.

```

#### A ShapeFile example

```
library(rgdal)

#read your shape file
path = 'mymaps'
file = 'myshapefile.shp'
layer = gsub(".shp","",file,ignore.case=TRUE)
data = readOGR(dsn=path, layer= layer)

#you may want to reproject the geometry to standard of your system
data = spTransform(data,CRS=CRS("+proj=longlat +datum=WGS84"))

#convert polygons to WKT geometry representation
library(rgeos)	
geom = writeWKT(data,byid=TRUE)

#prep import
names = data@data$name  #or the column name of the data
shape.to.odb = data.frame(name=names,datum='WSG84',geom=geom,stringsAsFactors = F)

#need to add the admin_level of these locations
shape.to.odb$admin_level = 2

#and may add parent and note if your want
odb_import_locations(data=shape.to.odb,odb_cfg=cfg)

```
#### Converting data from KML

```
#read file as SpatialPolygonDataFrame
file = "myfile.kml"
file.exists(file)
mykml = readOGR(file)
geom = writeWKT(mykml,byid=TRUE)

#prep import
names = mykml@data$name  #or the column name of the data
to.odb = data.frame(name=names,datum='WSG84',geom=geom,stringsAsFactors = F)

#need to add the admin_level of these locations
to.odb$admin_level = 2

#and may add parent or any other valid field

#import
odb_import_locations(data=to.odb,odb_cfg=cfg)

```

### Import Plots and subplots

Plots are a special case within OpenDataBio. They may have a geometry defined as any other location type, but may also have cartesian dimensions (X and Y) in meters. Subplots are plots within plot locations and may also have cartesian positions (startX, startY) within parent location in addition to dimensions. Cartesian position refer to X and Y positions within parent plot and hence MUST be smaller than parent X and Y.  And the same is true for Individuals within plots or subplots when they have their own X and Y cartesian coordinates.

You need at least a single point geographical coordinate for a plot or subplot location. Geometry (or lat and long) cannot be empty. However, it may prevent you from placing a subplot within a plot if both are point locations.  Hence, you should consider adding geometry as a polygon at least for plots when having subplots.

```
#import a 1ha plot with automatic parent location

#geometry of plot in Manaus
lats = c( -3.095764,  -3.094822, -3.094822,-3.095764)
longs = c(-59.987747, -59.987747, -59.986835,-59.986835)
geom = cbind(longs,lats)
geom = Polygon(geom)
geom = Polygons(list(geom), ID = 1)
geom = SpatialPolygons(list(geom))
geom = writeWKT(geom)
plot.to.odb = data.frame(name='My plot',x=100,y=100,notes='a fake plot',geom=geom, adm_level = 100,stringsAsFactors=F)
odb_import_locations(data=plot.to.odb,odb_cfg=cfg)

#import a 20x20m subplot to the plot above with cartesian coordinates and a point geometry
latitude = -3.095442
longitude= -59.987657
subplot.to.odb = data.frame(name='My subplot',x=20,y=20,lat=latitude, long=longitude, adm_level=100,startx=0,starty=20,stringsAsFactors=F)

#import
odb_import_locations(data=subplot.to.odb,odb_cfg=cfg)
```

### Importing latitude / longitude data
The most straightforward way to import spatial data is importing the latitude and longitude of
a point. You must convert the data to decimal representation, with positive values for North
and East, and negative values for South and West. For instance, a point in Brasilia (Brazil)
would have latitude of -15.64 and longitude of -46.87. The required fields to import locations
are name, adm\_level and either a latitude and longitude coordinate or a full `geom` object. 
You may specify a parent location for each object to speed up the process, but if you don't, 
it will be detected automatically. Other fields may also be imported, check the API documentation for more details.

To import some points to the database, you can write

```
lat = c(-9.9482, -7.2526, -12.3749)
long = c(-48.6371, -54.1272, -65.1819)
name = paste("GPS point", 1:3)
loclist = data.frame(name=name, lat=lat, long=long, adm_level = 999)
odb_import_locations(loclist, cfg)
```
## Importing persons

It is recommended you use the web interface, as it will warn you in case the person you want to register has a similar, likely the same, person already registered. The API will only check for identical Abbreviations, which is the single restriction of the Person class. Abbreviations are unique and duplication are not allowed. This does not prevent data downloaded from repositories to have different abbreviations or full name for the same person. So, you should standardize secondary data before importing into the server to minimize such common errors. 

```
to.odb = data.frame(full_name='Adolpho Ducke',abbreviation='DUCKE, A.',notes='Grande botânico da Amazônia',stringsAsFactors = F)
odb_import_persons(to.odb,odb_cfg=cfg)

#may also add an email entry if you have one

```

## Importing taxons

You can import a list of taxons using the `odb_import_taxons` function. For a successful importation of published names, you just need to provide a 'name' value, being the fullname for species and infraspecies categories (e.g. Licaria guianensis guianensis). You may also provide, 'level' and 'parent' to minimize assignment errors. The import process will use the "name" value to retrieve taxon info from a nomenclatural repository: Tropicos (Mobot), the International Plant Name Index (IPNI), Zoobank, Mycobank and GBIF. If found, it will automatically get the author, which is mandatory, and will detect the parent for the taxon. If the parent is not registered the importation will fail. If parent is informed and different from the one detected, then the informed parent may be used. For unpublished names, a `person` or `author_id` value must be provided.

Therefore, if you are trying to import a large number of published taxon names, should first check that parents are registered and import them first, but the API will tell you what is missing. Spelling errors in names my, therefore, prevent a taxon from being stored. When receiving a list of published taxonomic names at any level, it is often necessary to clean up typographical errors, capitalization, and other incorrect names. The package `taxize` can help with that, and may also help you get valid parent names for all Taxon levels, in case they are also not stored in your system. 

Taxonomy is hierarchical and the structure within the OpenDataBio may be treelike. So, you may add, if you want, any node from the tree of life into the Taxon table. For these you need to use the `Clade` taxon level. But note, this may not be relevant if you are not going link data to such clade name.

Unpublished names for species may also be recorded, but they require an author, which is a Person in the database. 

### Simple example
Check your name with taxize:
```
spp = c("Ficus Schultesii", "Ficus catingae", "Ficus caballina")
checked.spp = taxize::gnr_resolve(spp, canonical=TRUE, best_match_only=TRUE)[, c(1,5)]
checked.spp = as.data.frame(fixed,stringsAsFactor=F)
checked.spp

```
After the species list is cleaned up, it may be transformed into a `data.table` and imported:

```
spp = checked.spp$matched_name2
splist = data.frame(name=spp, level="species", parent_name="Ficus")
odb_import_taxons(splist, cfg)
```
For species and infraspecific categories parent_name must be provided, either as name or as a numeric id value that you may get with `odb_get_taxons`.

### Taxon and parents from Tropicos (MOBOT)
Import a Taxon and the full parent classification, retrieving data from Tropicos. The example also uploads the mobotid, the taxon publication reference and author, when available. Not that Tropicos classification for upper taxonomic levels may be outdated from current APG system.

```
#get taxon data from tropicos
tx = taxize::tp_search("Lauraceae",db='tropicos')
tx = as.data.frame(tx)

#get full classification hierarchy if not already in ODB
tx.class = taxize::classification(tx$nameid,db="tropicos")
tx.class = tx.class[[1]]

#helper to use taxize with apply
mytp_search <- function(x) {
    as.data.frame(taxize::tp_search(nameid=x,db='tropicos'),stringsAsFactors=F)
}
tx.class = lapply(tx.class$id,mytp_search)
tx.class = do.call(rbind,tx.class)

#join and get relevant columns
cls = c("nameid", "scientificname", "author", "displayreference","rankabbreviation")
tx.to.odb = rbind(tx.class[,cls],tx[,cls])
colnames(tx.to.odb ) = c("mobot","name","author","bibreference","level")

#get taxon levels as numeric values from ODB
codes = odb_taxonLevelCodes(level=tx.to.odb$adm_level)
sum(is.na(codes)) #all found
tx.to.odb$level = codes

#order your table following the hierarchy as you need to import parent before children
tx.to.odb = tx.to.odb[order(tx.to.odb$level),]

#add parents. Here, each line is a parent of the following and the first must be attached somewhere in the Taxon table
rootparent.name = "Spermatopsida"  #or whatever taxon already in data.base to assign the first as children
parents = c(rootparent.name,tx.to.odb$name[1:(nrow(tx.to.odb)-1)])
tx.to.odb$parent_name = parents

#import
odb_import_taxons(tx.to.odb,odb_cfg=cfg)

```

### An unpublished species or morphotype

It is common to have unpublished local species names (morphotypes) for plants in plots, or yet to be published taxonomic work. Unpublished designation are project specific and therefore MUST also provide an author as different projects may use the same 'sp.1' or 'sp.A' code for their unpublished taxons. 

You may link an unpublished name as any taxon level and do not need to use Genus+species logic to assign a morphotype for which the genus or upper level taxonomy is undefined. For example, you may store a 'species' level with name 'Indet sp.1' and parent_name 'Laurales', if the lowest level formal determination you have is the order level. In this example, there is no need to store a Indet genus and Indet family taxons just to account for this unidentified morphotype.

```
#assign an unpublished name for which you only know belongs to the Angiosperms and you have this node in the Taxon table already
#check that angiosperms exist 
odb_get_taxons(params=list(name='Angiosperms'),odb_cfg = cfg)

to.odb = data.frame(name='Morphotype sp.1', parent_name='Angiosperms', stringsAsFactors=F)

#get species level code
to.odb$level=odb_taxonLevelCodes('sp.')

#you must provide an author that is a Person in the Person table. Get from server
odb.persons = odb_get_people(params=list(search='name.to.search.here'),odb_cfg=cfg)

#found
head(odb.persons)

#add
to.odb$author = odb.persons$id

#import
odb_import_taxons(to.odb,odb_cfg = cfg)

```
### Import a published clade

You may add a clade Taxon and may reference its publication using the `bibkey` entry. So, it is possible to actually store all relevant nodes of any phylogeny in the Taxon hierarchy.

```
#parent must be stored already
odb_get_taxons(params=list(name='Pagamea'),odb_cfg = cfg)

#define clade Taxon
to.odb = data.frame(name='Guianensis core', parent_name='Pagamea', stringsAsFactors=F)
to.odb$level = odb_taxonLevelCodes('clade')

#add a reference to the publication where it is published 
#import bib reference to database beforehand
odb_get_bibreferences(params(bibkey='prataetal2018'),odb_cfg=cfg)
to.odb$bibkey = 'prataetal2018'

#then add valid species names as children of this clade instead of the genus level
children = data.frame(name = c('Pagamea guianensis','Pagamea angustifolia','Pagamea puberula'),stringsAsFactors=F)
children$parent_name = 'Guianensis core'
children$level = odb_taxonLevelCodes('species')
children$bibkey = NA

#merge
to.odb = rbind(to.odb,children)

#import
odb_import_taxons(to.odb,odb_cfg = cfg)

```
## Working with dates and incomplete dates

For individuals, vouchers and identifications you may use incomplete dates.

The date format used in OpenDataBio is year - month - day, so a valid entry would be '2018-05-28'.
In many older collections, the exact day (or month) is not known, so you can substitute this fields with NA: '1979-05-NA' means "an unknown day, in May 1979", and '1979-NA-NA' means "unknown day and month, 1979". You may not add a date for which you have only the day, but can if you have only the month if is actually meaningful in some way.

## Importing Individuals 

Individuals can be imported  using `odb_import_individuals()`.  Individuals must have an unique identifier defined by the combination of Tag+Collector+Location, which defines the individuals fullname. 

### Mandatory fields
1. tag = the number for the record, may be the aluminium tag on tree or bird ring, or the `collector number` of an herbarium specimen;
1. collectors = persons ids, abbreviations, fullnames or emails, as a string separated by ';' or '|', or list. Get ids with `odb_get_persons()`. The first person on the list is the `main collector`
1. date = complete or incomplete collecting date for the individual (see above). You may inform as separate fields: date_year, date_month, date_day, or just year,month, day;
1. project =  the project_id or name to which the individual will be linked and which you may get with `odb_get_projects()`.

### Individual location fields
**Mandatory**
1. location = id, or name of registered location
OR
1. latitude and longitude =  coordinates of record (will save a POINT location if it does not exists)
**Optional**
1. altitude = in meters above sea level;
1. location_notes = text;
1. location_date_time = complete date time string: YYYY-MM-DD HH:mm:ss
1. x = cartesian position within location (for PLOT type)
1. y = cartesian position within location (for PLOT type)
1. distance = distance in meters from location (for POINT type)
1. angle = azimuth in degrees from location (for POINT type)

### Individual identification fields (optional)
1. taxon =  the taxon id or name - get with `odb_get_taxons()`. 
1. identifier =  the person 'id', 'abbreviation', 'full_name', 'email' that made the identification. get with `odb_get_people()`. 
1. identification_date = complete or incomplete date, as string or name list (see above)
1. modifier =  if you need a modifier, use the numerical codes from `odb_detModifiers()`. Optional. Defaults to 0, 'none'.
1. identification_notes =  Optional, a text referring to the identification. 
1. identification_based_on_biocollection = Optional, when the identification comes from a comparison with an herbarium specimen, you may add here the acronym or id of the Biocollection, and the id number 
1. identification_based_on_biocollection_id = Optional. The  Biocollection id or reference code.

The last two fields allow you to link your identification to a specimen in a BioCollection and may be used to retrieve updates for the identification of the individual in your database. For this to be meaningful, `identification_based_on_biocollection_id` must be a somewhat permanent code that allows you to find it in the herbarium data repository(or GBIF, SpeciesLink, etc) in the future.

#### Individual vouchers (optional)
If Individual has Vouchers you may import them along with the Individual record by adding the biocollection references below. This is valid only if Voucher has the same collector and number (tag) as that of the Individual (else import them after importing Individuals with `odb_import_vouchers()`). 
1. biocollection = string of ids or acronyms separated by ';' or '|';
1. biocollection_number =  string of local reference codes separated by ';' or '|', same length as 'biocollection'
1. biocollection_type = string of numerical nomeclatural type codes separated by ';' or '|', same length as 'biocollection'. You may get the code list with `odb_nomenclaturalTypes()`

You may also specify this as a list or data.frame in the biocollection column, having three columns/elements:'biocollection_code','biocollection_number','biocollection_type'.

#### Individual example

```
basic.fields =  c("tag", "location", "tagging_team","relative_position","date")
identification.fields = c("taxon", "identifier", "modifier", "identification_date","identification_notes", "identification_based_on_herbarium","herbarium_code")

#a plant tag, the number in the aluminium tag in the forest
to.odb = data.frame(tag='3405.L1', stringsAsFactors=F)

#the tagging team (get ids from the server for member of the group tagging the plant)
joao = odb_get_people(params=list(search='joao batista'),odb_cfg=cfg)$id
ana = odb_get_people(params=list(search='ana andrade'),odb_cfg=cfg)$id
#ids concatenated by | pipe 
to.odb$collector = paste(joao,ana,sep='|')

#tagged date (may be incomplete).
to.odb$date = '2018-07-NA'

#location
to.odb$location = odb_get_locations(params=list(name='Plot 2021'),odb_cfg=cfg)$id

#relative position within parent 
to.odb$x = 10.4
to.odb$y = 32.5
#or could be
to.odb$relative_position = paste(x,y,sep=',')

#taxonomic identification with incomplete identification date
taxon = odb_get_taxons(params=list(name='Dinizia excelsa'),odb_cfg=cfg)$id

#person that identified the plant
to.odb$identifier = odb_get_persons(params=list(search='apostolo'),odb_cfg=cfg)$id

#may add modifers as well [may need to use numeric code instead]
to.odb$modifier = 'cf.'

#an incomplete identification date
to.odb$identification_date = list(year=2005) or just "2005-NA-NA"

odb_import_individuals(to.odb,odb_cfg = cfg)
```
#### An even simpler example

You may just use the code below, but will imply the following assumptions as identifications cannot be added without identifier nor identification_date: a) identifier will be the default Person associated with your profile; b) identification_date will be the same as date.

```
location = c("GPS point 2", "GPS point 1")
tag = c("001","002")
date = c("2017-08-09", "2017-05-NA")
taxon = c("Abarema acreana", "Aciotis olivieriana")
plantlist = data.frame(location=location, tag=tag, date=date, taxon=taxon, project="Rare species of the Para region")
odb_import_individuals(plantlist, cfg)
```

## Import Vouchers 

Vouchers are samples from Individuals, deposited in BioCollections. If the Biocollection is a genetic resource, the Voucher may just represent a DNA or tissue sample.

Therefore, Vouchers must belong to an Individual and to a BioCollection, which are the mandatory information to register vouchers. Collectors, collection date, location and taxonomic identity may be just extracted from the Individual's record. But a Voucher may have its own Collectors, CollectorNumber and CollectingDates, different from the Individual it belongs to. 

### Mandatory
1. individual = individual id or full name;
1. biocollection = acronym or id of the BioCollection;

### Optional 
1. biocollection_number = string of local reference codes separated by ';' or '|', same length as 'biocollection'
1. biocollection_type = string of numerical nomeclatural type codes separated by ';' or '|', same length as 'biocollection'. You may get the code list with `odb_nomenclaturalTypes()`
1. collector = list of ids, abbreviations, full_names or emails of persons, separated by ';' or '|';
1. number = the collector-number code;
1. date = complete or incomplete date for the Voucher collection
1. notes = any not you wish;


## Import Traits

Before importing any trait, make sure it is not already registered in the system with a different name. Preventing duplication is important as the Trait class is shared among all users of a OpenDataBio installation. This also means that once a trait is used to include Measurements, you may only alter the trait definition, for example, a category name, if you were the user entering the measurements. Otherwise, somebody else used that definition and you will not be able to alter.(CHECK API)

Use the web interface to add traits, it will be easier for you to include all possible language translations. 

Traits have one restriction: export_name must be unique. This name is used as a column name when exporting data and you should consider making it as short and informative (of definition) as possible and DO NOT add spaces or any special character. 

### Traits entries

See `odb_traitTypeCodes()` for possible trait types.

#### Mandatory
1. name - string for English or list for all languages, having the keys as the Language ids, see `odb_get_languages()` helper.
1. description - same as name
1. export_name - string
1. type - a 0 to 6 numeric code . Check `odb_traitTypeCodes()`;
1. objects - string containing to which object types the trait may be linked

#### Optional or trait specific
1. units - required for quantitative traits only (the unit o measurement), standard to English
1. range_min - optional for quantitative
1. range_max - optional for quantitative
1. cat_names - required for categorical; list of categories language translations
1. cat_descriptions - optional but recommended for categorical; list of categories descriptions translations
1. bibkey - optional, bibkey to link trait definition with reference in database

### Quantitative traits

For quantitative traits for either _integers_ or _real_ values (types 0 or 1). 
```
odb_traitTypeCodes()

#do this first to build a correct data.frame as it will include translations list
to.odb = data.frame(type=1,export_name = "DBH", units='centimeters',stringsAsFactors = F)

#add translations (note double list) 
#format is language_id = translation (and the column be a list with the translation lists)
to.odb$name[[1]]= list('1' = 'Diameter at breast height', '2' = 'Diâmetro à altura do peito')
to.odb$description[[1]]= list('1' = 'Stem diameter measured at 1.3m height, unless otherwise specified','2' = 'Diâmetro do tronco medido à 1.3m de altura, exceto quando especificado diferentemente em DBHPom')


#measurement validations
to.odb$range_min = 10  #this will restrict the minimum measurement value allowed in the trait
to.odb$range_max = 400 #this will restrict the maximum value

#measurements can be linked to (classes concatenated by , or a list)
to.odb$object = "Plants,Voucher,Taxon"  #makes no sense link such measurements to Locations

to.odb$notes = 'a fake note'

#import
odb_import_taxons(to.odb,odb_cfg=cfg)

```

### Categorical or ordinal traits

Must include categories. The only difference between ordinal and categorical traits is that ordinal categories will have a rank and the rank will be inferred from the order the categories are informed during importation. Note that ordinal traits are semiquantitative and so, if you have categories ask yourself whether they are not really ordinal and register accordingly.

Like the Trait name and description, categories may also have different language translations, and you SHOULD enter the translations for the languages available (`odb_get_languages()`) in the server, so the Trait will be accessible in all languages. English is mandatory, so at least the English name must be informed. Categories may have a description associated, but sometimes the category name is self explanatory, so descriptions of categories are not mandatory.

#### Multiselection categories
```
odb_traitTypeCodes()

#do this first to build a correct data.frame as it will include translations list
to.odb = data.frame(type=3,export_name = "SpecimenFertility", stringsAsFactors = F)

#trait name and description
to.odb$name =  data.frame("1"="Specimen Fertility","2"="Fertilidade do especímene",stringsAsFactors=F)
to.odb$description =  data.frame("1"="Kind of reproductive stage of a collected plant","2"="Estágio reprodutivo de uma amostra de planta coletada",stringsAsFactors=F)

#categories (if your trait is ORDINAL, the add categories in the wanted order here)
cat1 = c("Sterile","Estéril")
cat2 = c("Flowers","Flores")
cat1 = c("Sterile","Estéril")
cat2 = c("Flowers","Flores")
cat3 = c("Fruits","Fruitos")
cat4 = c("Flower buds","Botões florais")
cat5 = c("Immature fruits","Frutos imaturos")
categories = as.data.frame(rbind(cat1,cat2,cat3,cat4,cat5),stringsAsFactors=F)
colnames(categories) = c("1","2")
to.odb$cat_names = categories

#descriptions not included for categories as they are obvious, but you may add in the same way as names

#measurements can be linked to (classes concatenated by , or a list)
to.odb$object = "Plants,Voucher"  #makes no sense link such measurements to Locations or Taxon

to.odb$notes = 'a fake note'

#import
odb_import_taxons(to.odb,odb_cfg=cfg)
```

### Link type traits

Not included in the API. Use the web interface to register such trait.

Link types are traits that allow you link a Plant, Taxon or Voucher as a value measurement to another object. For example, you may conduct a plant inventory for which you have only counts for Taxon associated to a locality. Therefore, you may create a LINK trait, which will allow you to store the count values for any Taxon as measurements for a particular location (POINT, POLYGON). Or you may link such values to Vouchers instead of Taxons if you have a representative specimen for the taxons.


### Text and color traits

Text and color traits require the minimum fields only for trait registration. Text traits allow the storage of textual observations. Color will only allow color codes (see under Measurements)

```
odb_traitTypeCodes()

to.odb = data.frame(type=5,export_name = "TaxonDescription", stringsAsFactors = F)

#trait name and description
to.odb$name =  data.frame("1"="Taxonomic descriptions","2"="Descrições taxonômicas",stringsAsFactors=F)
to.odb$description =  data.frame("1"="Taxonomic descriptions from the literature","2"="Descrições taxonômicas da literatura",stringsAsFactors=F)

#will only be able to use this trait for a measurment associated with a Taxon
to.odb$object = "Taxon"

#import
odb_import_taxons(to.odb,odb_cfg=cfg)

```
### Spectral traits

Spectral traits are specific to spectral data. You must specify the range of wavenumber values for which you may have absorbance or reflectance data, and the length of the spectra to be stored as measurements to allow validation during input. So, for each range and spacement of the spectral values you have, a different SPECTRAL trait must be created.

### Genebank trait

To be included in OpenDataBio - a link of a voucher or individua to a specific GeneBank accession.


## Import Measurements  (Data into Datasets)

Measurements are straightforward. You need to provide a dataset (for which you do have permissions), trait_id, value (content varies depending on trait type), date (a complete or incomplete date), person (id of person that measured), object_type (taxon, plant, voucher or location) and object_id. For LINK trait type, you must provide a link_id column, and 'value' becomes optional for this specific case.

Measurement have one restriction in the API: duplicated measurements values or categories for the same object_id and date will not be imported, unless you specify a 'duplicated=1' entry in the import table.

TIP: To link measurements in different traits you may add standard keys to the 'note' measurement field. For example, you measure LeafLength and LeafWidth from the same leaves, so in both cases add "leaf1" ,"leaf2", .. to the note field. Also, you measure DBH and DBH.POM in a forest plot inventory and have several stems for a plant, you may add "stem1","stem2" to permit matching a stem DBH to its specific height of measurement. This kind of link may be useful in analyses.

Several validations will happen during measurement importation. Consider verifying locality before submitting a job to facilitate troubleshooting and guarantee the values are consistent with your expectations. You will not be able to UPDATE measurements with the API, so, avoid importing several measurements that will require fixing afterwards (one by one).

### Columns for measurements

#### Mandatory

1. trait_id - the trait_id or export_name
1. value - depends on trait type (see examples) - optional for LINK trait type
1. date - the date the measurement was made (fundamental for monitoring)
1. object_type - one of c("Plant","Voucher","Taxon", "Location") - must be in Trait definition
1. object_id - the id of the object
1. dataset  - the name or id of the dataset to include the measurement (use id)
1. person - the id of the person (single person) that did measurement
1. bibreference - either a bibkey or a bib_id for a BibReference in the system
1. link_id - only for LINK_TYPE traits - must be the id to the type of LINK the trait refers to

#### Optional
1. notes - any note you want, but see TIP above
1. duplicated - with value 1 to allow duplicated measurements in the same date for the sabe object and trait

### Quantitative measurements

OpenDataBio will not be able to test whether your measurements are in the same unit as the Trait definition. Therefore, check which unit the trait has, and convert accordingly before uploading your data.

```
#get the trait id from the server (check that trait exists)
odbtraits = odb_get_traits(odb_cfg=cfg)
(m = match(c("DBH","DBHpom"),odbtraits$export_name))
to.odb = data.frame(trait_id = odbtraits$id[m], value = c(24.5,1.3), date = '2020-07-31', object_type = 'Plant', stringsAsFactors=F)

to.odb$notes = "stem1΅ #both are from the same

#check MEASUREMENT UNIT for trait and make sure your data conform, otherwise convert
odbtraits$unit[m]

#get plant id from API (must be ID not tag. If you add a tag and there is an id matching the tag, the measurement will be misplaced.
odbplant = odb_get_plants(params=list(tag='1234'),odb_cfg=cfg)
head(odbplant)
to.odb$object_id = odbplant$id

#get dataset id
odbdatasets = odb_get_datasets(params=list(name='Plot data'),odb_cfg=cfg)
head(odbdatasets)
to.odb$dataset = odbdataset$id

#person that measured
odbperson = odb_get_people(params=list(search='chalom'),odb_cfg=cfg)
odbperson
to.odb$person = odbperson$id

odb_import_measurements(to.odb,odb_cfg=cfg)
```
### Categorical measurements

Categories MUST be informed by their ids in the value field. For CATEGORICAL or ORDINAL traits, value may have a single id. For CATEGORICAL_MULTIPLE, may be one or multiple categories ids, that may be a string with ids separated by commas or list with the ids as values.

```
#get the trait id from the server (check that trait exists)
odbtraits = odb_get_traits(odb_cfg=cfg)
(m = match(c("SpecimenFertility"),odbtraits$export_name))

#base line
to.odb = data.frame(trait_id = odbtraits$id[m], date = '2020-07-31', stringsAsFactors=F)

#the plant was collected with both flowers and fruits
value = c("Flowers","Fruits")

#get categories for this trait if found
(cats = odbtraits$categories[m][[1]])

#check that your categories are registered for the trait and get their ids
value = cats[match(value,cats$name),'id']

#make multiple categories ids a string value
value = paste(value,collapse=",")
to.odb$value = value

#this links to a specimen
to.odb$object_type = "Voucher"
#get voucher id from API (must be ID). Search for collection number 1234
odbspecs = odb_get_vouchers(params=list(number='1234'),odb_cfg=cfg)
odbspecs$fullname
to.odb$object_id = odbspecs$id[1]

#get dataset id
odbdatasets = odb_get_datasets(params=list(name='Collected specimens attributes'),odb_cfg=cfg)
head(odbdatasets)
to.odb$dataset = odbdataset$id

#person that measured
odbperson = odb_get_people(params=list(search='chalom'),odb_cfg=cfg)
odbperson
to.odb$person = odbperson$id

odb_import_measurements(to.odb,odb_cfg=cfg)

```

### Color measurements

For color values you have to enter color as their 'hex RGB strings' codes. Therefore, any color value is allowed, and it would be easier to use the palette colors in the web interface to enter such measurements. Package `gplots` allows you to convert color names to hex RGB codes if you want to do it through the API.

```
#get the trait id from the server (check that trait exists)
odbtraits = odb_get_traits(odb_cfg=cfg)
(m = match(c("FruitMainColor"),odbtraits$export_name))

#base line
to.odb = data.frame(trait_id = odbtraits$id[m], date = '2020-07-31', stringsAsFactors=F)

#get color value
library(gplots)
(value =  col2hex("red"))
to.odb$value = value

#this links to a specimen
to.odb$object_type = "Voucher"
#get voucher id from API (must be ID). Search for collection number 1234
odbspecs = odb_get_vouchers(params=list(number='1234'),odb_cfg=cfg)
odbspecs$fullname
to.odb$object_id = odbspecs$id[1]

#get dataset id
odbdatasets = odb_get_datasets(params=list(name='Collected specimens attributes'),odb_cfg=cfg)
head(odbdatasets)
to.odb$dataset = odbdataset$id

#person that measured
odbperson = odb_get_people(params=list(search='chalom'),odb_cfg=cfg)
odbperson
to.odb$person = odbperson$id

odb_import_measurements(to.odb,odb_cfg=cfg)

```
### Database link type measurements

```
#get the trait id from the server (check that trait exists)
odbtraits = odb_get_traits(odb_cfg=cfg)
(m = match(c("TaxonCount"),odbtraits$export_name))

#base line
to.odb = data.frame(trait_id = odbtraits$id[m], date = '2020-07-31', stringsAsFactors=F)

#the taxon to link the count value
odbtax = odb_get_taxons(params=list(name='Euterpe precatoria'),odb_cfg=cfg)
to.odb$link_id = odbtax$id

#now add the count value for this trait type 
#this is optional for this measurement, however, it would make no sense to include such link without a count in this example
to.odb$value = 23 

#a note to clarify the measurement (optional)
to.odb$notes = 'First15minInterval' 

#this measurement will link to a location
to.odb$object_type = "Location"
#get voucher id from API (must be ID). Search for collection number 1234
odblocs = odb_get_vouchers(params=list(name='Trilha do Pajurá'),odb_cfg=cfg)
odblocs
to.odb$object_id = odblocs$id[1]

#get dataset id
odbdatasets = odb_get_datasets(params=list(name='Rapid count inventory at some site'),odb_cfg=cfg)
head(odbdatasets)
to.odb$dataset = odbdataset$id

#person that measured
odbperson = odb_get_people(params=list(search='chalom'),odb_cfg=cfg)
odbperson
to.odb$person = odbperson$id

odb_import_measurements(to.odb,odb_cfg=cfg)

```
### Spectral measurements

Value must be a string with spectrum values separated by ";"

The number of values must match the Trait value_length attribute. So, you may easily check this before importing, getting traits with `odb_get_traits(params=list(fields='all'),cfg)`

Otherwise, proceed as above.

### Text measurements

Just add the text to the value field and proceed as above.

